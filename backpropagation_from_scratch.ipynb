{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "hungarian-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "elegant-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-brass",
   "metadata": {},
   "source": [
    "Overview of the calculations going on throughout:\n",
    "We take the X matrix which has all the values indicating greyscale (so betweeen 0 & 1 where 0 is fully white and 1 is fully black). We multiply it by a weight then add a bias to get our Z1 value (the 1 indicating its in the first layer excluding input layer). Note we randomise the values of weight and bias first time round and then use backpropagation to refine our choice of their values [ I THINK!]. This is fed into our activation function (which can vary, we use ReLu and softmax here) to get A1. These are the values in the first layer.\n",
    "They are then multiplied by another weight and a bias is added to get Z2. Z2 isd fed into an activation function to get A2. In our case, as we only choose to have 1 hidden layer, A2 here is the output layer so it indicates which number we think is drawn in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "auburn-corrections",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "hollywood-addiction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "hundred-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "m, n = data.shape # this sets m = number of inputs in training data and n = numbe of features in each input +1 (+1 because the shape also include the label i.e. which number the image is)\n",
    "np.random.shuffle(data) # shuffle before splitting into dev and training sets\n",
    "\n",
    "data_dev = data[0:1000].T # next we split the training set so we have a subsection to do dev with. Don't want to do dev with training data bc when we come to training the model after it will have already seen these inputs.\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:n]\n",
    "X_dev = X_dev / 255.\n",
    "\n",
    "data_train = data[1000:m].T  # note that transposing means that now each column represents an input\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255.\n",
    "_,m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "subsequent-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(z1_size, A_size): #note that here z1_size is the number of neurons in the first layer. A_size is the number of neurons in output layer (will be 10 here as there's 10 possible outputs)\n",
    "    w1 = np.random.rand(z1_size, 784) - 0.5 # subtract 0.5 here because np.random.rand generates number between 0 & 1, we want values between -0.5 & 0.5\n",
    "    b1 = np.random.rand(A_size, 1) - 0.5\n",
    "    w2 = np.random.rand (z1_size, A_size) - 0.5\n",
    "    b2 = np.random.rand(A_size, 1) - 0.5\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "located-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    return np.maximum(0,Z) \n",
    "\n",
    "def softmax(Z):\n",
    "    return np.exp(Z) / sum(np.exp(Z))\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1)) # creates array of zeros with dimensions = no. of inputs (aka \"m\" or Y.size here) by the numober of potential outputs (Y.max() + 1 = 9+1=10)\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1 # np.arange (NOT arrange!) goes through the range of values between 0 and Y.size. \"Y\" takes the particualr value of Y for that inoput. Puts a 1 at this index\n",
    "    one_hot_Y = one_hot_Y.T # this now means each COLUMN will be a n input example\n",
    "    return one_hot_Y\n",
    "    \n",
    "def deriv_relu(Z):\n",
    "    return Z > 0 #if False, this will be converted to 0 which is the slope of a horizontal line on graph. If True, this will be convered to 1 which is slope of linear line\n",
    "\n",
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2)\n",
    "    dZ1 = W2.T.dot(dZ2) * deriv_relu(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1)\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1- alpha * db1\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2- alpha * db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "combined-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = init_params(10, 10)\n",
    "    for i in range(iterations): # we now apply the functions created above iteratively\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i % 10 == 0: # here we will check the accuracy every 10th iteration\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "instructional-violin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[1 1 5 ... 2 5 5] [4 9 3 ... 1 6 3]\n",
      "0.09480487804878049\n",
      "Iteration:  10\n",
      "[7 4 8 ... 6 2 8] [4 9 3 ... 1 6 3]\n",
      "0.19702439024390245\n",
      "Iteration:  20\n",
      "[7 4 3 ... 6 2 8] [4 9 3 ... 1 6 3]\n",
      "0.29321951219512193\n",
      "Iteration:  30\n",
      "[7 4 3 ... 6 2 8] [4 9 3 ... 1 6 3]\n",
      "0.39078048780487806\n",
      "Iteration:  40\n",
      "[7 4 3 ... 6 6 8] [4 9 3 ... 1 6 3]\n",
      "0.44858536585365855\n",
      "Iteration:  50\n",
      "[7 4 3 ... 1 6 8] [4 9 3 ... 1 6 3]\n",
      "0.4960731707317073\n",
      "Iteration:  60\n",
      "[9 4 3 ... 1 6 8] [4 9 3 ... 1 6 3]\n",
      "0.5325609756097561\n",
      "Iteration:  70\n",
      "[9 4 3 ... 1 6 8] [4 9 3 ... 1 6 3]\n",
      "0.5640731707317073\n",
      "Iteration:  80\n",
      "[9 4 3 ... 1 6 8] [4 9 3 ... 1 6 3]\n",
      "0.5880243902439024\n",
      "Iteration:  90\n",
      "[9 4 3 ... 1 6 8] [4 9 3 ... 1 6 3]\n",
      "0.6098536585365854\n",
      "Iteration:  100\n",
      "[9 4 3 ... 1 6 8] [4 9 3 ... 1 6 3]\n",
      "0.6299512195121951\n",
      "Iteration:  110\n",
      "[9 4 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.6484390243902439\n",
      "Iteration:  120\n",
      "[9 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.6645121951219513\n",
      "Iteration:  130\n",
      "[9 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.6793658536585366\n",
      "Iteration:  140\n",
      "[9 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.6929024390243902\n",
      "Iteration:  150\n",
      "[9 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.7057073170731707\n",
      "Iteration:  160\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.7178048780487805\n",
      "Iteration:  170\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.7287073170731707\n",
      "Iteration:  180\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.7380487804878049\n",
      "Iteration:  190\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.7474390243902439\n",
      "Iteration:  200\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.7555609756097561\n",
      "Iteration:  210\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.7631463414634146\n",
      "Iteration:  220\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.7698048780487805\n",
      "Iteration:  230\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.775\n",
      "Iteration:  240\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.7807317073170732\n",
      "Iteration:  250\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.7857317073170732\n",
      "Iteration:  260\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.7903902439024391\n",
      "Iteration:  270\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.7945365853658537\n",
      "Iteration:  280\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.7983902439024391\n",
      "Iteration:  290\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8023414634146342\n",
      "Iteration:  300\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8060487804878049\n",
      "Iteration:  310\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8093902439024391\n",
      "Iteration:  320\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8129512195121951\n",
      "Iteration:  330\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8162926829268292\n",
      "Iteration:  340\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8184634146341463\n",
      "Iteration:  350\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8212682926829268\n",
      "Iteration:  360\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8237073170731707\n",
      "Iteration:  370\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.826\n",
      "Iteration:  380\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8284878048780487\n",
      "Iteration:  390\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8306829268292683\n",
      "Iteration:  400\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8325609756097561\n",
      "Iteration:  410\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8345853658536585\n",
      "Iteration:  420\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8363170731707317\n",
      "Iteration:  430\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8381219512195122\n",
      "Iteration:  440\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8399268292682927\n",
      "Iteration:  450\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8421219512195122\n",
      "Iteration:  460\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8438048780487805\n",
      "Iteration:  470\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8451951219512195\n",
      "Iteration:  480\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8464390243902439\n",
      "Iteration:  490\n",
      "[4 9 3 ... 1 6 3] [4 9 3 ... 1 6 3]\n",
      "0.8476829268292683\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.1, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "limited-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = X_train[:, index, None]\n",
    "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2)\n",
    "    label = Y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    \n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "sufficient-peter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [4]\n",
      "Label:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(2, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "laughing-salad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 7 0 5 5 4 7 7 9 2 1 6 9 2 5 4 7 1 0 1 6 7 6 3 3 6 9 6 2 6 1 8 9 0 2 7 9\n",
      " 9 3 1 2 1 0 5 8 9 6 4 9 5 2 6 1 7 2 9 9 3 3 9 3 6 4 6 6 8 2 4 1 2 1 9 7 2\n",
      " 9 2 6 0 1 0 9 2 1 5 4 4 6 0 3 4 4 4 9 3 1 4 8 9 4 3 7 0 7 7 3 4 6 3 3 7 8\n",
      " 1 0 1 0 5 6 4 4 7 9 9 0 3 6 1 6 1 7 4 0 8 8 5 2 4 0 6 6 3 0 6 9 5 4 7 6 9\n",
      " 1 3 8 9 1 1 9 6 6 2 9 0 4 2 0 7 1 4 3 2 7 8 9 2 4 0 6 7 0 6 5 6 6 0 0 3 6\n",
      " 3 8 6 1 8 2 2 9 3 3 7 6 5 5 0 2 2 3 2 7 5 8 0 1 3 4 5 5 6 7 0 0 6 4 0 1 8\n",
      " 9 8 2 4 1 9 4 6 1 9 6 9 4 2 6 7 0 7 9 4 9 0 0 2 1 1 8 1 7 6 7 5 4 4 2 8 9\n",
      " 1 3 4 9 5 3 5 7 8 2 0 0 6 3 3 7 1 1 5 6 8 4 4 3 3 8 7 3 6 4 9 3 5 7 0 7 1\n",
      " 1 9 4 4 2 7 3 9 8 6 3 9 0 1 0 5 7 5 6 8 2 2 2 7 9 4 8 5 4 1 7 4 4 6 4 3 6\n",
      " 8 3 7 7 1 8 3 9 1 3 9 1 2 2 5 6 6 4 4 2 7 1 6 5 6 7 9 2 9 8 6 6 3 3 8 1 7\n",
      " 4 2 9 4 9 9 4 2 6 4 3 2 9 9 0 9 1 6 9 7 7 4 9 7 5 7 7 5 8 1 1 5 3 4 8 0 2\n",
      " 9 5 8 6 9 3 5 9 3 6 2 3 3 6 3 6 5 4 1 6 6 3 9 5 4 5 2 4 3 5 6 3 9 2 0 2 4\n",
      " 1 1 8 4 6 0 2 0 0 1 0 6 6 9 1 7 9 6 9 7 5 1 1 9 3 8 1 9 0 3 3 7 7 0 3 3 2\n",
      " 5 5 9 2 1 3 2 3 6 6 2 2 1 4 3 4 8 6 5 4 1 2 2 6 7 8 6 0 7 6 7 6 2 6 8 7 9\n",
      " 6 9 2 8 8 8 8 1 5 5 2 3 2 1 8 2 7 8 5 8 1 1 2 6 6 3 7 5 7 3 3 5 0 7 1 5 1\n",
      " 7 1 3 4 5 3 6 9 2 1 6 5 1 3 0 7 1 9 2 8 2 8 0 1 4 8 3 0 3 1 4 1 4 8 2 7 6\n",
      " 1 3 3 4 2 2 8 1 8 7 1 4 9 9 7 3 1 1 7 4 0 1 2 3 3 8 5 7 7 9 7 5 7 3 2 9 5\n",
      " 0 7 4 5 8 5 3 4 8 9 7 4 0 2 5 3 6 1 5 2 4 1 1 8 8 9 7 9 2 7 5 2 5 5 1 0 3\n",
      " 2 9 7 3 8 7 1 4 3 6 1 1 2 1 0 2 0 1 3 2 4 6 8 3 4 7 2 0 5 3 6 1 4 4 7 6 3\n",
      " 5 2 3 9 6 1 2 2 9 3 8 5 6 3 2 0 9 9 4 4 4 0 5 8 0 2 8 1 8 1 3 1 1 6 9 0 7\n",
      " 6 2 8 0 0 0 1 6 2 8 6 9 3 3 0 4 4 9 6 6 3 9 2 0 4 8 1 0 7 9 6 8 3 2 1 1 3\n",
      " 9 6 2 9 0 3 1 2 6 6 3 6 5 1 9 0 9 6 7 9 0 1 7 9 9 4 4 6 3 7 2 5 0 8 2 2 7\n",
      " 7 4 8 9 1 0 5 9 4 8 1 9 6 5 9 3 2 7 1 7 8 8 5 9 1 2 0 0 9 0 8 9 3 7 0 8 5\n",
      " 7 0 1 4 7 5 4 4 1 6 2 5 3 7 6 0 0 7 0 2 1 7 3 4 0 6 4 0 7 4 5 9 5 6 8 5 9\n",
      " 2 0 4 7 7 5 6 6 6 9 8 9 8 8 0 3 4 6 1 4 7 2 7 4 0 9 8 3 6 4 6 9 8 7 4 3 4\n",
      " 2 0 9 6 4 8 1 0 2 3 6 5 5 4 2 1 6 2 6 6 1 6 6 0 4 2 3 0 2 2 3 9 2 7 4 2 8\n",
      " 7 9 2 3 5 1 8 0 7 3 3 1 5 5 8 1 7 1 7 3 6 7 0 5 3 6 5 4 0 5 0 4 3 6 1 6 0\n",
      " 5] [5 7 0 8 5 8 7 7 9 2 1 8 4 2 5 4 7 1 0 6 6 5 6 8 3 6 9 6 2 6 1 8 9 0 2 7 9\n",
      " 8 8 1 2 1 0 9 8 9 6 4 8 5 2 6 1 7 2 9 8 3 3 9 3 6 4 6 6 8 2 4 1 3 7 7 7 2\n",
      " 9 2 6 0 1 0 5 2 1 5 4 4 6 0 5 6 4 4 4 8 1 1 8 9 4 3 7 0 7 7 3 4 6 3 3 7 8\n",
      " 1 0 8 0 5 6 4 4 7 1 9 0 3 6 1 6 1 7 4 0 8 8 5 2 4 0 6 8 3 0 6 9 5 4 7 6 9\n",
      " 1 3 3 9 1 1 2 2 6 2 9 0 4 2 0 7 1 4 3 7 7 8 9 2 6 0 6 7 0 6 3 6 6 0 0 3 6\n",
      " 2 8 6 1 8 2 2 9 2 3 7 6 5 0 0 2 2 3 2 7 5 8 0 1 3 4 5 3 6 7 0 0 6 4 0 1 8\n",
      " 8 4 2 4 1 9 4 6 3 9 6 9 4 2 6 3 0 7 9 4 9 0 0 2 1 1 8 1 7 6 2 5 4 8 2 8 4\n",
      " 1 3 4 9 8 3 5 7 8 2 0 0 6 3 3 7 1 1 5 6 8 4 4 3 3 8 7 3 6 4 9 3 5 7 0 7 1\n",
      " 1 7 4 4 2 7 3 7 8 6 3 9 0 1 3 5 7 5 6 8 2 2 2 9 9 4 8 3 9 1 7 4 4 6 4 3 6\n",
      " 8 3 7 7 1 8 3 4 1 3 9 1 2 2 5 6 6 4 5 2 7 1 6 5 6 9 9 2 9 9 6 6 3 3 8 1 7\n",
      " 4 3 9 4 9 9 4 2 6 6 3 2 9 4 0 9 1 6 9 7 7 4 9 7 5 7 7 5 3 1 1 0 3 4 8 0 2\n",
      " 9 5 8 9 9 3 3 9 3 6 2 8 3 6 2 6 5 4 1 6 6 3 9 5 4 5 2 4 3 3 6 5 9 2 0 2 9\n",
      " 1 1 8 4 6 2 2 0 0 1 0 2 6 3 1 7 4 6 9 7 5 1 1 9 5 6 1 9 0 3 3 7 7 0 3 3 2\n",
      " 5 5 9 2 1 3 2 3 6 6 2 2 1 9 3 4 8 6 5 4 1 2 2 6 7 8 6 0 7 6 7 6 2 6 8 7 9\n",
      " 2 9 2 8 5 8 8 1 5 5 8 0 2 1 8 7 2 8 5 8 1 1 2 6 6 3 7 5 7 3 5 5 0 7 1 5 1\n",
      " 7 8 0 4 5 0 6 9 2 1 6 5 1 3 0 9 1 9 2 8 2 8 0 1 4 8 3 0 5 1 4 1 4 3 2 7 6\n",
      " 1 3 3 4 2 2 8 1 8 7 1 4 9 9 7 3 1 1 7 4 0 1 2 3 8 8 5 7 7 9 4 5 7 3 2 9 5\n",
      " 0 9 4 5 8 5 3 9 3 9 7 4 0 2 5 3 6 1 5 2 4 1 1 8 8 9 7 9 2 7 5 2 7 5 3 0 3\n",
      " 3 7 7 3 8 2 1 4 3 6 1 1 2 1 0 8 5 8 3 8 4 6 8 3 4 7 2 0 5 9 6 9 4 4 0 6 3\n",
      " 5 2 8 9 6 1 5 2 9 3 2 9 6 3 2 0 9 4 9 4 4 0 8 8 0 2 5 1 8 1 5 1 1 8 9 0 7\n",
      " 6 2 8 0 0 0 1 6 2 8 6 4 3 9 0 4 4 4 6 6 0 8 4 0 4 8 1 0 7 8 5 8 7 2 1 2 5\n",
      " 9 6 4 4 0 3 1 3 6 6 3 6 5 1 9 0 9 6 7 9 0 1 9 9 9 4 4 6 8 3 2 5 4 8 2 2 2\n",
      " 7 4 2 4 1 6 5 9 4 5 1 9 6 5 9 2 2 7 1 7 8 8 5 7 1 2 0 0 7 0 8 8 3 7 0 5 5\n",
      " 7 0 1 4 7 5 4 4 1 6 2 5 7 7 6 0 0 7 0 2 1 7 3 4 0 6 4 0 7 4 5 9 5 6 1 5 5\n",
      " 2 0 4 7 7 5 6 6 6 9 8 9 8 8 0 3 4 6 7 4 6 2 7 4 0 9 8 3 6 4 4 9 8 7 4 3 6\n",
      " 7 6 7 6 4 8 1 0 2 3 6 5 5 4 2 1 6 2 6 6 1 6 2 0 4 2 3 0 3 2 3 9 2 7 9 2 8\n",
      " 7 9 2 3 8 1 8 0 7 3 3 1 5 5 8 1 7 1 7 3 6 7 0 5 3 6 6 4 0 5 0 4 3 6 1 6 0\n",
      " 8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.845"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_predictions = make_predictions(X_dev, W1, b1, W2, b2)\n",
    "get_accuracy(dev_predictions, Y_dev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
